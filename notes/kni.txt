1ï¸âƒ£ What is KNI in DPDK?

KNI = Kernel NIC Interface

It is a mechanism that allows DPDK user-space applications to communicate with the Linux kernel networking stack.

Simple idea

DPDK normally:

Bypasses the Linux kernel

Works fully in user space

Gives very high packet speed

But sometimes we still need:

Linux tools like ping, tcpdump, iptables

Kernel routing / ARP / IP stack

Control-plane communication

ğŸ‘‰ KNI was created to connect:

DPDK user space  â†”  Linux kernel network stack


So packets can move between kernel and DPDK.

2ï¸âƒ£ Why KNI was needed?

Because pure DPDK has no kernel networking.

Without KNI:

No ifconfig

No ping

No kernel routing

No standard sockets

So KNI allowed:

Control-plane in kernel

Data-plane in DPDK

This was very useful in:

Early NFV (Network Function Virtualization)

Routers/firewalls using DPDK

Telecom packet processing

3ï¸âƒ£ KNI Architecture
Components
1. Kernel Module (rte_kni.ko)

Runs inside Linux kernel.

Responsibilities:

Creates virtual network interface (like kni0)

Sends/receives packets to/from DPDK

Handles ioctl/configuration

2. User-space Library (librte_kni)

Used by DPDK app.

Responsibilities:

Allocate shared memory

Send packets to kernel

Receive packets from kernel

Handle requests from kernel

3. Shared Memory + FIFO Queues

Packets move via:

DPDK mbufs â†’ shared memory â†’ kernel skbuff
kernel skbuff â†’ shared memory â†’ DPDK mbuf


Using:

RX queue

TX queue

Allocation/free queues

Request queue

This avoids copying packets, improving speed.

4ï¸âƒ£ How KNI Works (Step-by-Step Packet Flow)
Case A â€” Packet from NIC â†’ Kernel via KNI
Step-by-step

NIC receives packet.

DPDK poll-mode driver gets packet â†’ mbuf.

DPDK app decides:

Forward?

Drop?

Send to kernel?

If send to kernel:

Call rte_kni_tx_burst()

Packet goes:

mbuf â†’ shared memory â†’ kernel module â†’ sk_buff â†’ Linux stack


Now Linux tools can see it:

tcpdump

ping

iptables

Case B â€” Packet from Kernel â†’ DPDK

Linux sends packet via kni0 interface.

Kernel converts:

sk_buff â†’ shared memory


DPDK reads using:

rte_kni_rx_burst()


Packet becomes mbuf and processed in fast path.

5ï¸âƒ£ Advantages of KNI
âœ” 1. Kernel compatibility

Can use:

ping

tcpdump

routing table

sockets

firewall rules

âœ” 2. Hybrid architecture
Control plane â†’ Kernel
Data plane â†’ DPDK


Very useful in NFV routers & firewalls.

âœ” 3. Easy debugging

You can:

Capture packets

Use standard Linux tools

âœ” 4. No full packet copy

Uses shared memory + zero-copy style transfer â†’ faster than TAP.

6ï¸âƒ£ Disadvantages of KNI
âŒ 1. Requires kernel module

Bad for:

Security

Maintainability

Containers

Cloud environments

Modern systems avoid custom kernel modules.

âŒ 2. Poor performance vs pure user-space

Still involves:

Kernel scheduling

Context interaction

Synchronization overhead

So slower than:

pure DPDK

AF_XDP

virtio-user

memif

âŒ 3. Complex synchronization

Needs:

Locks

FIFOs

Request handling

Hard to maintain â†’ many bugs historically.

âŒ 4. Not scalable for multi-core high PPS

KNI becomes bottleneck in:

100G traffic

many cores

7ï¸âƒ£ Why KNI is Deprecated

DPDK officially deprecated KNI because:

1. Kernel module maintenance burden

Linux kernel changes frequently â†’ KNI breaks.

Maintaining out-of-tree module = huge effort.

2. Better modern alternatives exist
âœ” AF_XDP

Kernel-supported

Zero-copy

No custom module

High performance

âœ” virtio-user + vhost

Standard virtualization method

âœ” memif (used in VPP)

High-speed shared memory interface

These are:

faster

safer

maintained

3. Security concerns

Custom kernel module = risk in production/cloud.

Cloud providers do not allow KNI.

8ï¸âƒ£ What replaces KNI today?

Modern replacements:

AF_XDP â†’ main successor

TAP + XDP

virtio-user

memif (VPP)

So industry moved away from KNI.

9ï¸âƒ£ Real-world analogy (easy understanding)

Think:

DPDK = high-speed private highway

Linux kernel = normal city roads

KNI = small connecting bridge

Old bridge:

slow

hard to maintain

unsafe

Now replaced by modern flyovers (AF_XDP, memif).

ğŸ”Ÿ Interview-ready summary
Definition

KNI is a DPDK mechanism to exchange packets between user-space DPDK and Linux kernel networking stack using shared memory and kernel module.

Why deprecated

Because:

Needs kernel module

Hard to maintain

Lower performance

Security issues

Replaced by AF_XDP / virtio / memif



1ï¸âƒ£ What is Data Plane and Control Plane?

Think of a router or firewall doing two different kinds of work.

ğŸŸ¢ Data Plane (Fast Path)
Meaning

The data plane is responsible for:

â¡ Forwarding packets as fast as possible

It does no complex thinking, only:

Look at packet header

Decide output port

Send packet immediately

Key points

Runs at very high speed

Uses DPDK / ASIC / hardware acceleration

Handles millions of packets per second

Must be simple and optimized

Example

When a packet arrives:

Check destination IP â†’ find route â†’ send to next port


That is data plane work.

ğŸ”µ Control Plane (Brain of the Network)
Meaning

The control plane decides HOW packets should be forwarded.

It:

Builds routing tables

Runs protocols like:

OSPF

BGP

ARP

Configures firewall/NAT rules

Handles management & configuration

Speed

Slow but intelligent

Runs in Linux kernel or user processes

ğŸ§  Easy Real-life Analogy

Think of a city traffic system:

Control plane â†’ traffic police + traffic rules
(decides where vehicles should go)

Data plane â†’ actual cars moving on roads
(fast movement, no thinking)

2ï¸âƒ£ Where does DPDK fit?

DPDK is designed for:

â¡ Data plane only (ultra-fast packet forwarding)

It bypasses Linux kernel to gain speed.

But then problem:

â— Linux kernel = control plane
â— DPDK = data plane

They cannot talk directly.

ğŸ‘‰ KNI was created to connect them.

3ï¸âƒ£ Is KNI used only when sending packets from Kernel â†’ DPDK?

No.
KNI works in both directions.

Direction 1 â€” DPDK â†’ Kernel

Used when:

Packet must be processed by Linux stack

Need:

ping

tcpdump

routing

iptables

sockets

Flow:

NIC â†’ DPDK â†’ KNI â†’ Linux kernel â†’ application

Direction 2 â€” Kernel â†’ DPDK

Used when:

Linux application sends packet via kni0

Packet must go to fast DPDK forwarding path

Flow:

Linux app â†’ kernel stack â†’ KNI â†’ DPDK â†’ NIC


ğŸ‘‰ So KNI is bidirectional, not only kernelâ†’DPDK.

4ï¸âƒ£ Why was KNI deprecated? (Very Important)

DPDK officially deprecated KNI.
Here are the real technical reasons.

âŒ 1. Requires custom kernel module

KNI depends on:

rte_kni.ko  (external kernel module)


Problems:

Linux kernel changes frequently

Module breaks with new kernels

Hard to maintain

Not allowed in many cloud/container environments

ğŸ‘‰ Modern design avoids out-of-tree kernel modules.

âŒ 2. Security risks

Custom kernel module means:

Runs in kernel space

Any bug â†’ kernel crash or exploit

Cloud providers:

AWS

Azure

GCP

â¡ Do NOT allow KNI.

âŒ 3. Performance is not good enough today

Although faster than TAP:

KNI still has:

Kernel interaction overhead

Synchronization cost

Not scalable for 100G+ traffic

Bottleneck in multi-core systems

Modern alternatives are:

AF_XDP â†’ zero-copy, kernel-native

memif (VPP) â†’ shared memory, faster

virtio-user/vhost â†’ standard virtualization path

ğŸ‘‰ These are faster and cleaner.

âŒ 4. Complex and hard to maintain

KNI includes:

FIFOs

locks

request handling

mbuf â†” skb conversion

This created:

bugs

maintenance burden

unstable behavior across kernels

DPDK team decided:

â¡ Not worth maintaining anymore.

âŒ 5. Industry moved to kernel-supported tech

Modern Linux networking prefers:

XDP / eBPF

AF_XDP sockets

standard virtio

So KNI became:

â¡ obsolete design.

5ï¸âƒ£ Short Interview-Ready Answers
Data plane

Fast packet forwarding path (DPDK, hardware, ASIC).

Control plane

Routing decisions, protocols, configuration (Linux/kernel/user apps).

Is KNI only kernelâ†’DPDK?

No.
It is bidirectional:

DPDK â†’ kernel

kernel â†’ DPDK

Why deprecated?

Main reasons:

Needs external kernel module

Security risks

Poor scalability & performance vs AF_XDP

Hard to maintain with new kernels

Replaced by modern kernel-native technologies